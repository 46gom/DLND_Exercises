{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 문제 해결 (과소적합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(32, use_bias=False)\n",
    "        self.batch1 = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.batch2 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense2 = tf.keras.layers.Dense(32, use_bias=False)\n",
    "        \n",
    "        self.batch3 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense3 = tf.keras.layers.Dense(64, use_bias=False)\n",
    "\n",
    "        self.batch4 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense4 = tf.keras.layers.Dense(128, use_bias=False)\n",
    "        \n",
    "        self.dense5 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = self.batch1(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        h = self.batch2(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense2(h)\n",
    "        x = tf.concat([x, h], axis=-1)\n",
    "        \n",
    "        h = self.batch3(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense3(h)\n",
    "        x = tf.concat([x, h], axis=-1)\n",
    "        \n",
    "        h = self.batch4(x, training)\n",
    "        h = tf.nn.relu(h)\n",
    "        h = self.dense4(h)\n",
    "        x = tf.concat([x, h], axis=-1)\n",
    "        \n",
    "        return self.dense5(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(2048)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras API 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.5117 - accuracy: 0.8161 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3983 - accuracy: 0.8550 - val_loss: 0.4601 - val_accuracy: 0.8383\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3648 - accuracy: 0.8673 - val_loss: 0.4235 - val_accuracy: 0.8524\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3452 - accuracy: 0.8739 - val_loss: 0.4324 - val_accuracy: 0.8403\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3298 - accuracy: 0.8791 - val_loss: 0.3873 - val_accuracy: 0.8578\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3197 - accuracy: 0.8823 - val_loss: 0.3839 - val_accuracy: 0.8695\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3088 - accuracy: 0.8862 - val_loss: 0.3629 - val_accuracy: 0.8677\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2999 - accuracy: 0.8902 - val_loss: 0.3852 - val_accuracy: 0.8572\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2923 - accuracy: 0.8920 - val_loss: 0.3746 - val_accuracy: 0.8684\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2862 - accuracy: 0.8943 - val_loss: 0.3731 - val_accuracy: 0.8711\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2803 - accuracy: 0.8962 - val_loss: 0.3656 - val_accuracy: 0.8721\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2716 - accuracy: 0.8997 - val_loss: 0.3467 - val_accuracy: 0.8780\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2702 - accuracy: 0.8989 - val_loss: 0.3543 - val_accuracy: 0.8784\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2649 - accuracy: 0.9013 - val_loss: 0.3696 - val_accuracy: 0.8713\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2613 - accuracy: 0.9027 - val_loss: 0.3644 - val_accuracy: 0.8723\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2577 - accuracy: 0.9044 - val_loss: 0.3920 - val_accuracy: 0.8608\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2507 - accuracy: 0.9059 - val_loss: 0.3704 - val_accuracy: 0.8716\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2504 - accuracy: 0.9058 - val_loss: 0.3722 - val_accuracy: 0.8706\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2479 - accuracy: 0.9059 - val_loss: 0.3601 - val_accuracy: 0.8778\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2448 - accuracy: 0.9079 - val_loss: 0.3685 - val_accuracy: 0.8750\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2414 - accuracy: 0.9086 - val_loss: 0.3490 - val_accuracy: 0.8791\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2384 - accuracy: 0.9110 - val_loss: 0.3777 - val_accuracy: 0.8757\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2352 - accuracy: 0.9116 - val_loss: 0.3749 - val_accuracy: 0.8708\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2317 - accuracy: 0.9132 - val_loss: 0.3533 - val_accuracy: 0.8806\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2315 - accuracy: 0.9131 - val_loss: 0.3540 - val_accuracy: 0.8836\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2276 - accuracy: 0.9145 - val_loss: 0.3807 - val_accuracy: 0.8754\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2277 - accuracy: 0.9144 - val_loss: 0.3513 - val_accuracy: 0.8823\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2254 - accuracy: 0.9157 - val_loss: 0.3780 - val_accuracy: 0.8771\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2211 - accuracy: 0.9163 - val_loss: 0.3855 - val_accuracy: 0.8758\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2205 - accuracy: 0.9168 - val_loss: 0.3652 - val_accuracy: 0.8813\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2174 - accuracy: 0.9178 - val_loss: 0.4085 - val_accuracy: 0.8642\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2133 - accuracy: 0.9194 - val_loss: 0.3773 - val_accuracy: 0.8768\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2145 - accuracy: 0.9176 - val_loss: 0.3693 - val_accuracy: 0.8808\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2150 - accuracy: 0.9180 - val_loss: 0.3754 - val_accuracy: 0.8746\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2093 - accuracy: 0.9209 - val_loss: 0.3923 - val_accuracy: 0.8727\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2078 - accuracy: 0.9202 - val_loss: 0.3820 - val_accuracy: 0.8716\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2086 - accuracy: 0.9204 - val_loss: 0.3869 - val_accuracy: 0.8780\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2034 - accuracy: 0.9230 - val_loss: 0.3784 - val_accuracy: 0.8786\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2027 - accuracy: 0.9233 - val_loss: 0.4083 - val_accuracy: 0.8710\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2032 - accuracy: 0.9230 - val_loss: 0.3705 - val_accuracy: 0.8809\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2009 - accuracy: 0.9236 - val_loss: 0.3628 - val_accuracy: 0.8864\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2002 - accuracy: 0.9241 - val_loss: 0.3823 - val_accuracy: 0.8806\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1979 - accuracy: 0.9245 - val_loss: 0.4035 - val_accuracy: 0.8699\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1978 - accuracy: 0.9254 - val_loss: 0.3861 - val_accuracy: 0.8751\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1964 - accuracy: 0.9251 - val_loss: 0.3947 - val_accuracy: 0.8774\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1960 - accuracy: 0.9266 - val_loss: 0.3883 - val_accuracy: 0.8822\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1919 - accuracy: 0.9276 - val_loss: 0.4073 - val_accuracy: 0.8743\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1956 - accuracy: 0.9259 - val_loss: 0.3725 - val_accuracy: 0.8812\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1925 - accuracy: 0.9275 - val_loss: 0.3973 - val_accuracy: 0.8762\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1912 - accuracy: 0.9273 - val_loss: 0.4031 - val_accuracy: 0.8732\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1910 - accuracy: 0.9279 - val_loss: 0.4310 - val_accuracy: 0.8645\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1912 - accuracy: 0.9278 - val_loss: 0.3938 - val_accuracy: 0.8730\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1866 - accuracy: 0.9284 - val_loss: 0.4158 - val_accuracy: 0.8779\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1852 - accuracy: 0.9295 - val_loss: 0.3936 - val_accuracy: 0.8762\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1863 - accuracy: 0.9291 - val_loss: 0.4145 - val_accuracy: 0.8732\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1843 - accuracy: 0.9304 - val_loss: 0.4006 - val_accuracy: 0.8821\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1851 - accuracy: 0.9302 - val_loss: 0.4101 - val_accuracy: 0.8736\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1825 - accuracy: 0.9315 - val_loss: 0.4158 - val_accuracy: 0.8736\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1823 - accuracy: 0.9312 - val_loss: 0.3806 - val_accuracy: 0.8818\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1806 - accuracy: 0.9324 - val_loss: 0.4224 - val_accuracy: 0.8673\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1784 - accuracy: 0.9324 - val_loss: 0.4134 - val_accuracy: 0.8748\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1776 - accuracy: 0.9329 - val_loss: 0.4060 - val_accuracy: 0.8818\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1788 - accuracy: 0.9326 - val_loss: 0.4184 - val_accuracy: 0.8757\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1771 - accuracy: 0.9334 - val_loss: 0.4016 - val_accuracy: 0.8799\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1786 - accuracy: 0.9329 - val_loss: 0.3938 - val_accuracy: 0.8785\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1769 - accuracy: 0.9337 - val_loss: 0.4155 - val_accuracy: 0.8767\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1756 - accuracy: 0.9334 - val_loss: 0.4097 - val_accuracy: 0.8774\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1742 - accuracy: 0.9346 - val_loss: 0.4205 - val_accuracy: 0.8828\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1734 - accuracy: 0.9340 - val_loss: 0.4094 - val_accuracy: 0.8835\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1720 - accuracy: 0.9343 - val_loss: 0.4052 - val_accuracy: 0.8814\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1737 - accuracy: 0.9347 - val_loss: 0.4370 - val_accuracy: 0.8705\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1714 - accuracy: 0.9346 - val_loss: 0.4120 - val_accuracy: 0.8743\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1709 - accuracy: 0.9342 - val_loss: 0.4133 - val_accuracy: 0.8756\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1691 - accuracy: 0.9360 - val_loss: 0.4364 - val_accuracy: 0.8771\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1672 - accuracy: 0.9361 - val_loss: 0.4348 - val_accuracy: 0.8705\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1699 - accuracy: 0.9355 - val_loss: 0.4226 - val_accuracy: 0.8750\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1687 - accuracy: 0.9352 - val_loss: 0.4239 - val_accuracy: 0.8784\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1680 - accuracy: 0.9364 - val_loss: 0.4366 - val_accuracy: 0.8741\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1692 - accuracy: 0.9357 - val_loss: 0.4268 - val_accuracy: 0.8744\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1652 - accuracy: 0.9373 - val_loss: 0.4311 - val_accuracy: 0.8708\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1666 - accuracy: 0.9370 - val_loss: 0.4163 - val_accuracy: 0.8768\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1644 - accuracy: 0.9377 - val_loss: 0.4316 - val_accuracy: 0.8770\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1652 - accuracy: 0.9368 - val_loss: 0.4423 - val_accuracy: 0.8735\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1637 - accuracy: 0.9370 - val_loss: 0.4307 - val_accuracy: 0.8708\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1623 - accuracy: 0.9385 - val_loss: 0.4435 - val_accuracy: 0.8702\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1628 - accuracy: 0.9380 - val_loss: 0.4283 - val_accuracy: 0.8737\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1615 - accuracy: 0.9388 - val_loss: 0.4538 - val_accuracy: 0.8754\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1616 - accuracy: 0.9397 - val_loss: 0.4493 - val_accuracy: 0.8756\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1605 - accuracy: 0.9387 - val_loss: 0.4690 - val_accuracy: 0.8694\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1602 - accuracy: 0.9392 - val_loss: 0.4378 - val_accuracy: 0.8790\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1601 - accuracy: 0.9389 - val_loss: 0.4398 - val_accuracy: 0.8803\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1576 - accuracy: 0.9402 - val_loss: 0.4808 - val_accuracy: 0.8660\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1606 - accuracy: 0.9395 - val_loss: 0.4508 - val_accuracy: 0.8763\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1590 - accuracy: 0.9402 - val_loss: 0.4400 - val_accuracy: 0.8749\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1547 - accuracy: 0.9407 - val_loss: 0.4704 - val_accuracy: 0.8722\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1546 - accuracy: 0.9404 - val_loss: 0.4740 - val_accuracy: 0.8680\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1558 - accuracy: 0.9413 - val_loss: 0.4776 - val_accuracy: 0.8720\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.1567 - accuracy: 0.9411 - val_loss: 0.4652 - val_accuracy: 0.8742\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1573 - accuracy: 0.9409 - val_loss: 0.4673 - val_accuracy: 0.8746\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1563 - accuracy: 0.9421 - val_loss: 0.4394 - val_accuracy: 0.8756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13b7f0a58>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnd",
   "language": "python",
   "name": "dlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
