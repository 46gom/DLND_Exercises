{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실전 문제 해결 (과적합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLNReluBock(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(ConvLNReluBock, self).__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
    "        self.ln = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv(x)\n",
    "        x = self.ln(x)\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "# Define network architecture\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1_1 = ConvLNReluBock(16, (3, 3))\n",
    "        self.conv1_2 = ConvLNReluBock(16, (3, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "\n",
    "        self.conv2_1 = ConvLNReluBock(32, (3, 3))\n",
    "        self.conv2_2 = ConvLNReluBock(32, (3, 3))\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D((2, 2))\n",
    "\n",
    "        self.conv3_1 = ConvLNReluBock(64, (3, 3))\n",
    "        self.conv3_2 = ConvLNReluBock(64, (3, 3))\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(1024, activation='relu', \n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax',\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 697s 4us/step\n"
     ]
    }
   ],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000).batch(32).prefetch(1024)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32).prefetch(1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras API 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 2.1967 - accuracy: 0.3981 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 1.2805 - accuracy: 0.5889 - val_loss: 1.2031 - val_accuracy: 0.6180\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 1.0841 - accuracy: 0.6605 - val_loss: 1.0222 - val_accuracy: 0.6761\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 0.9772 - accuracy: 0.6989 - val_loss: 1.0243 - val_accuracy: 0.6797\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 255s 163ms/step - loss: 0.9202 - accuracy: 0.7181 - val_loss: 0.9965 - val_accuracy: 0.6937\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 236s 151ms/step - loss: 0.8703 - accuracy: 0.7389 - val_loss: 0.9061 - val_accuracy: 0.7222\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.8249 - accuracy: 0.7510 - val_loss: 0.8443 - val_accuracy: 0.7462\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 260s 167ms/step - loss: 0.7879 - accuracy: 0.7670 - val_loss: 0.8595 - val_accuracy: 0.7465\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 266s 170ms/step - loss: 0.7587 - accuracy: 0.7783 - val_loss: 0.8281 - val_accuracy: 0.7570\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 246s 157ms/step - loss: 0.7307 - accuracy: 0.7856 - val_loss: 0.8143 - val_accuracy: 0.7613\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 241s 154ms/step - loss: 0.7062 - accuracy: 0.7930 - val_loss: 0.7845 - val_accuracy: 0.7704\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 358s 229ms/step - loss: 0.6889 - accuracy: 0.8035 - val_loss: 0.7899 - val_accuracy: 0.7735\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 286s 183ms/step - loss: 0.6656 - accuracy: 0.8105 - val_loss: 0.8173 - val_accuracy: 0.7560\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 214s 137ms/step - loss: 0.6450 - accuracy: 0.8174 - val_loss: 0.7923 - val_accuracy: 0.7715\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 200s 128ms/step - loss: 0.6291 - accuracy: 0.8235 - val_loss: 0.7582 - val_accuracy: 0.7844\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 198s 127ms/step - loss: 0.6133 - accuracy: 0.8279 - val_loss: 0.7756 - val_accuracy: 0.7730\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 196s 126ms/step - loss: 0.5948 - accuracy: 0.8339 - val_loss: 0.7901 - val_accuracy: 0.7782\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 196s 126ms/step - loss: 0.5786 - accuracy: 0.8414 - val_loss: 0.7717 - val_accuracy: 0.7792\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 195s 125ms/step - loss: 0.5674 - accuracy: 0.8454 - val_loss: 0.7673 - val_accuracy: 0.7863\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 198s 127ms/step - loss: 0.5553 - accuracy: 0.8491 - val_loss: 0.7934 - val_accuracy: 0.7757\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 197s 126ms/step - loss: 0.5395 - accuracy: 0.8546 - val_loss: 0.7836 - val_accuracy: 0.7778\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 197s 126ms/step - loss: 0.5192 - accuracy: 0.8612 - val_loss: 0.7743 - val_accuracy: 0.7800\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 206s 132ms/step - loss: 0.5137 - accuracy: 0.8639 - val_loss: 0.7688 - val_accuracy: 0.7851\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 195s 125ms/step - loss: 0.5014 - accuracy: 0.8689 - val_loss: 0.7565 - val_accuracy: 0.7879\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.4885 - accuracy: 0.8733 - val_loss: 0.7810 - val_accuracy: 0.7827\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 194s 124ms/step - loss: 0.4740 - accuracy: 0.8795 - val_loss: 0.7898 - val_accuracy: 0.7768\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 193s 123ms/step - loss: 0.4671 - accuracy: 0.8819 - val_loss: 0.8145 - val_accuracy: 0.7736\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 197s 126ms/step - loss: 0.4522 - accuracy: 0.8864 - val_loss: 0.8065 - val_accuracy: 0.7835\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 195s 125ms/step - loss: 0.4405 - accuracy: 0.8919 - val_loss: 0.7930 - val_accuracy: 0.7833\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 196s 126ms/step - loss: 0.4352 - accuracy: 0.8927 - val_loss: 0.8052 - val_accuracy: 0.7912\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 201s 129ms/step - loss: 0.4263 - accuracy: 0.8966 - val_loss: 0.8370 - val_accuracy: 0.7726\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 209s 133ms/step - loss: 0.4170 - accuracy: 0.9009 - val_loss: 0.8058 - val_accuracy: 0.7899\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 210s 134ms/step - loss: 0.4041 - accuracy: 0.9050 - val_loss: 0.8336 - val_accuracy: 0.7813\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 205s 131ms/step - loss: 0.3988 - accuracy: 0.9068 - val_loss: 0.9003 - val_accuracy: 0.7683\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 207s 132ms/step - loss: 0.3900 - accuracy: 0.9103 - val_loss: 0.8851 - val_accuracy: 0.7718\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 210s 134ms/step - loss: 0.3848 - accuracy: 0.9112 - val_loss: 0.8694 - val_accuracy: 0.7771\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 206s 132ms/step - loss: 0.3817 - accuracy: 0.9128 - val_loss: 0.8373 - val_accuracy: 0.7822\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 208s 133ms/step - loss: 0.3661 - accuracy: 0.9196 - val_loss: 0.8312 - val_accuracy: 0.7905\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 209s 134ms/step - loss: 0.3598 - accuracy: 0.9204 - val_loss: 0.8481 - val_accuracy: 0.7872\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 206s 132ms/step - loss: 0.3568 - accuracy: 0.9212 - val_loss: 0.8596 - val_accuracy: 0.7807\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 211s 135ms/step - loss: 0.3511 - accuracy: 0.9237 - val_loss: 0.8772 - val_accuracy: 0.7839\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 208s 133ms/step - loss: 0.3435 - accuracy: 0.9269 - val_loss: 0.9351 - val_accuracy: 0.7703\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 209s 134ms/step - loss: 0.3420 - accuracy: 0.9275 - val_loss: 0.8913 - val_accuracy: 0.7802\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 210s 134ms/step - loss: 0.3337 - accuracy: 0.9298 - val_loss: 0.9080 - val_accuracy: 0.7808\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 211s 135ms/step - loss: 0.3277 - accuracy: 0.9319 - val_loss: 0.9027 - val_accuracy: 0.7826\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 211s 135ms/step - loss: 0.3247 - accuracy: 0.9331 - val_loss: 0.9000 - val_accuracy: 0.7826\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 224s 143ms/step - loss: 0.3135 - accuracy: 0.9383 - val_loss: 0.9002 - val_accuracy: 0.7799\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 0.3135 - accuracy: 0.9364 - val_loss: 0.9606 - val_accuracy: 0.7760\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 229s 146ms/step - loss: 0.3022 - accuracy: 0.9410 - val_loss: 0.9376 - val_accuracy: 0.7804\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 0.3019 - accuracy: 0.9415 - val_loss: 0.9309 - val_accuracy: 0.7812\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 211s 135ms/step - loss: 0.2999 - accuracy: 0.9411 - val_loss: 0.9628 - val_accuracy: 0.7748\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 214s 137ms/step - loss: 0.2966 - accuracy: 0.9431 - val_loss: 0.9406 - val_accuracy: 0.7757\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 214s 137ms/step - loss: 0.2899 - accuracy: 0.9444 - val_loss: 0.9380 - val_accuracy: 0.7826\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 214s 137ms/step - loss: 0.2878 - accuracy: 0.9459 - val_loss: 0.9133 - val_accuracy: 0.7855\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 209s 134ms/step - loss: 0.2812 - accuracy: 0.9477 - val_loss: 0.9376 - val_accuracy: 0.7744\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 210s 134ms/step - loss: 0.2811 - accuracy: 0.9481 - val_loss: 0.9463 - val_accuracy: 0.7828\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 210s 135ms/step - loss: 0.2793 - accuracy: 0.9477 - val_loss: 0.9572 - val_accuracy: 0.7727\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2702 - accuracy: 0.9516 - val_loss: 0.9663 - val_accuracy: 0.7803\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 233s 149ms/step - loss: 0.2716 - accuracy: 0.9501 - val_loss: 0.9763 - val_accuracy: 0.7797\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 234s 150ms/step - loss: 0.2718 - accuracy: 0.9515 - val_loss: 0.9659 - val_accuracy: 0.7756\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 235s 151ms/step - loss: 0.2658 - accuracy: 0.9528 - val_loss: 0.9750 - val_accuracy: 0.7782\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 236s 151ms/step - loss: 0.2651 - accuracy: 0.9537 - val_loss: 1.0263 - val_accuracy: 0.7790\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2564 - accuracy: 0.9556 - val_loss: 1.0282 - val_accuracy: 0.7805\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2624 - accuracy: 0.9536 - val_loss: 0.9881 - val_accuracy: 0.7804\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 0.2564 - accuracy: 0.9562 - val_loss: 1.0111 - val_accuracy: 0.7766\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2488 - accuracy: 0.9584 - val_loss: 1.0920 - val_accuracy: 0.7658\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2534 - accuracy: 0.9569 - val_loss: 1.0098 - val_accuracy: 0.7754\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2496 - accuracy: 0.9585 - val_loss: 1.0390 - val_accuracy: 0.7704\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2445 - accuracy: 0.9595 - val_loss: 0.9946 - val_accuracy: 0.7722\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 238s 153ms/step - loss: 0.2464 - accuracy: 0.9589 - val_loss: 0.9978 - val_accuracy: 0.7786\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 237s 152ms/step - loss: 0.2417 - accuracy: 0.9605 - val_loss: 0.9948 - val_accuracy: 0.7714\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2419 - accuracy: 0.9592 - val_loss: 1.0232 - val_accuracy: 0.7798\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 220s 140ms/step - loss: 0.2428 - accuracy: 0.9597 - val_loss: 1.0628 - val_accuracy: 0.7758\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 219s 140ms/step - loss: 0.2396 - accuracy: 0.9606 - val_loss: 1.0304 - val_accuracy: 0.7821\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 217s 139ms/step - loss: 0.2357 - accuracy: 0.9615 - val_loss: 1.0422 - val_accuracy: 0.7778\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 217s 139ms/step - loss: 0.2327 - accuracy: 0.9623 - val_loss: 1.0766 - val_accuracy: 0.7761\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 217s 139ms/step - loss: 0.2311 - accuracy: 0.9634 - val_loss: 1.1069 - val_accuracy: 0.7724\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 217s 139ms/step - loss: 0.2259 - accuracy: 0.9645 - val_loss: 1.0534 - val_accuracy: 0.7840\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 218s 139ms/step - loss: 0.2293 - accuracy: 0.9634 - val_loss: 1.0464 - val_accuracy: 0.7734\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 216s 138ms/step - loss: 0.2324 - accuracy: 0.9625 - val_loss: 1.0283 - val_accuracy: 0.7748\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 218s 139ms/step - loss: 0.2167 - accuracy: 0.9681 - val_loss: 1.0394 - val_accuracy: 0.7797\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 217s 139ms/step - loss: 0.2287 - accuracy: 0.9624 - val_loss: 1.0433 - val_accuracy: 0.7775\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 233s 149ms/step - loss: 0.2258 - accuracy: 0.9633 - val_loss: 1.0968 - val_accuracy: 0.7773\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 240s 153ms/step - loss: 0.2169 - accuracy: 0.9668 - val_loss: 1.1014 - val_accuracy: 0.7731\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 0.2217 - accuracy: 0.9649 - val_loss: 1.0884 - val_accuracy: 0.7792\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 0.2098 - accuracy: 0.9691 - val_loss: 1.0930 - val_accuracy: 0.7746\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2261 - accuracy: 0.9634 - val_loss: 1.1196 - val_accuracy: 0.7614\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2100 - accuracy: 0.9685 - val_loss: 1.1025 - val_accuracy: 0.7701\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2146 - accuracy: 0.9664 - val_loss: 1.0943 - val_accuracy: 0.7749\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 238s 152ms/step - loss: 0.2113 - accuracy: 0.9681 - val_loss: 1.0992 - val_accuracy: 0.7669\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 0.2088 - accuracy: 0.9686 - val_loss: 1.1182 - val_accuracy: 0.7747\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2131 - accuracy: 0.9672 - val_loss: 1.0892 - val_accuracy: 0.7773\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 240s 153ms/step - loss: 0.2052 - accuracy: 0.9697 - val_loss: 1.1466 - val_accuracy: 0.7658\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2138 - accuracy: 0.9665 - val_loss: 1.0533 - val_accuracy: 0.7735\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2017 - accuracy: 0.9715 - val_loss: 1.1700 - val_accuracy: 0.7703\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 240s 154ms/step - loss: 0.2040 - accuracy: 0.9698 - val_loss: 1.1898 - val_accuracy: 0.7583\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 239s 153ms/step - loss: 0.2048 - accuracy: 0.9698 - val_loss: 1.0530 - val_accuracy: 0.7749\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 220s 140ms/step - loss: 0.2027 - accuracy: 0.9704 - val_loss: 1.0645 - val_accuracy: 0.7846\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 209s 134ms/step - loss: 0.2012 - accuracy: 0.9707 - val_loss: 1.0732 - val_accuracy: 0.7812\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 209s 134ms/step - loss: 0.1995 - accuracy: 0.9709 - val_loss: 1.1131 - val_accuracy: 0.7792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13df65f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlnd",
   "language": "python",
   "name": "dlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
